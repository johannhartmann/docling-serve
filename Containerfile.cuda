ARG BASE_IMAGE=nvidia/cuda:12.4.1-cudnn-devel-ubuntu22.04

FROM ${BASE_IMAGE}

USER 0

###################################################################################################
# OS Layer                                                                                        #
###################################################################################################

# Install Python 3.12 and other dependencies
RUN apt-get update && \
    apt-get install -y software-properties-common && \
    add-apt-repository ppa:deadsnakes/ppa && \
    apt-get update && \
    apt-get install -y \
        python3.12 python3.12-dev python3.12-venv python3.12-distutils \
        python3-pip git gcc g++ make \
        tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd \
        libtesseract-dev libleptonica-dev \
        libgl1-mesa-glx && \
    update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.12 1 && \
    update-alternatives --set python3 /usr/bin/python3.12 && \
    rm -rf /var/lib/apt/lists/*

# Install pip for Python 3.12
RUN curl -sS https://bootstrap.pypa.io/get-pip.py | python3.12

WORKDIR /opt/app-root/src

ENV \
    # On container environments, always set a thread budget to avoid undesired thread congestion.\
    OMP_NUM_THREADS=4 \
    LANG=en_US.UTF-8 \
    LC_ALL=en_US.UTF-8 \
    PYTHONIOENCODING=utf-8 \
    TRANSFORMERS_VERBOSITY=info \
    UV_COMPILE_BYTECODE=1 \
    UV_LINK_MODE=copy \
    UV_PROJECT_ENVIRONMENT=/opt/app-root \
    DOCLING_SERVE_ARTIFACTS_PATH=/opt/app-root/src/.cache/docling/models \
    CUDA_HOME=/usr/local/cuda \
    TESSDATA_PREFIX=/usr/share/tesseract-ocr/5/tessdata/

ARG UV_SYNC_EXTRA_ARGS=""
ARG DOCLING_VLM_QUANTIZE_8BIT
ENV DOCLING_VLM_QUANTIZE_8BIT=${DOCLING_VLM_QUANTIZE_8BIT}

# Install uv
RUN curl -LsSf https://astral.sh/uv/0.7.19/install.sh | sh && \
    mv /root/.local/bin/uv /usr/local/bin/

# Install dependencies
COPY pyproject.toml uv.lock ./
RUN uv sync --frozen --no-install-project --no-dev --all-extras --no-extra flash-attn

# Clone and install flash-attention from source
RUN git clone https://github.com/Dao-AILab/flash-attention.git /tmp/flash-attention && \
    cd /tmp/flash-attention && \
    pip install flash-attn . --no-build-isolation && \
    rm -rf /tmp/flash-attention

ARG MODELS_LIST="layout tableformer picture_classifier easyocr smoldocling qwenvl"

RUN echo "Downloading models..." && \
    HF_HUB_DOWNLOAD_TIMEOUT="90" \
    HF_HUB_ETAG_TIMEOUT="90" \
    docling-tools models download -o "${DOCLING_SERVE_ARTIFACTS_PATH}" ${MODELS_LIST}

COPY ./docling_serve ./docling_serve
RUN uv sync --frozen --no-dev --all-extras

# Create a non-root user
RUN useradd -m -u 1001 -s /bin/bash appuser && \
    chown -R 1001:0 /opt/app-root && \
    chmod -R g=u /opt/app-root

USER 1001

EXPOSE 5001

CMD ["docling-serve", "run"]