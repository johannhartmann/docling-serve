# syntax=docker/dockerfile:1.4
# Multi-stage build for flash-attention from source with optimizations
ARG CUDA_VERSION=12.4.1
ARG PYTHON_VERSION=3.12

# Stage 1: Build flash-attention
FROM nvidia/cuda:${CUDA_VERSION}-cudnn-devel-ubuntu22.04 AS flash-attn-builder

ARG PYTHON_VERSION=3.12

# Install Python and minimal build dependencies
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked \
    --mount=type=cache,target=/var/lib/apt,sharing=locked \
    DEBIAN_FRONTEND=noninteractive apt-get update && apt-get install -y --no-install-recommends \
    software-properties-common \
    git \
    curl \
    ca-certificates \
    && add-apt-repository ppa:deadsnakes/ppa \
    && DEBIAN_FRONTEND=noninteractive apt-get update && apt-get install -y --no-install-recommends \
    python${PYTHON_VERSION} \
    python${PYTHON_VERSION}-dev \
    python${PYTHON_VERSION}-venv \
    && rm -rf /var/lib/apt/lists/*

# Set Python 3.12 as default and install pip
RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 1 && \
    curl -sS https://bootstrap.pypa.io/get-pip.py | python3

# Install PyTorch with CUDA support (cached)
RUN --mount=type=cache,target=/root/.cache/pip,sharing=locked \
    pip3 install torch==2.6.0+cu124 --index-url https://download.pytorch.org/whl/cu124

# Set build optimization flags
ENV CUDA_HOME=/usr/local/cuda \
    MAX_JOBS=4 \
    MAKEFLAGS=-j4 \
    TORCH_CUDA_ARCH_LIST="7.0;7.5;8.0;8.6;8.9;9.0"

# Clone and build flash-attention wheel only (no install)
WORKDIR /build
RUN --mount=type=cache,target=/root/.cache/pip,sharing=locked \
    git clone --depth 1 https://github.com/Dao-AILab/flash-attention.git && \
    cd flash-attention && \
    pip3 wheel flash-attn . --no-build-isolation -w /wheels

# Stage 2: Download models in parallel
FROM python:3.12-slim AS model-downloader

# Install git (required for some pip packages)
RUN apt-get update && apt-get install -y --no-install-recommends git && \
    rm -rf /var/lib/apt/lists/*

# Install uv
RUN pip install uv

# Copy project files to install docling with correct dependencies
COPY pyproject.toml uv.lock ./

# Install docling and dependencies to get docling-tools
# Need to set UV_PROJECT_ENVIRONMENT to install globally
ENV UV_PROJECT_ENVIRONMENT=/usr/local
RUN uv sync --frozen --no-install-project --no-dev --all-extras

# Download models
ARG MODELS_LIST="layout tableformer picture_classifier easyocr smoldocling qwenvl"
ENV HF_HUB_DOWNLOAD_TIMEOUT=90 \
    HF_HUB_ETAG_TIMEOUT=90

RUN --mount=type=cache,target=/root/.cache/huggingface,sharing=locked \
    /usr/local/bin/docling-tools models download -o /models ${MODELS_LIST}

# Stage 3: Runtime image with CUDA runtime
FROM nvidia/cuda:${CUDA_VERSION}-cudnn-runtime-ubuntu22.04

ARG PYTHON_VERSION=3.12

# Install Python and runtime dependencies in one layer
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked \
    --mount=type=cache,target=/var/lib/apt,sharing=locked \
    DEBIAN_FRONTEND=noninteractive apt-get update && apt-get install -y --no-install-recommends \
    software-properties-common \
    curl \
    ca-certificates \
    && add-apt-repository ppa:deadsnakes/ppa \
    && DEBIAN_FRONTEND=noninteractive apt-get update && apt-get install -y --no-install-recommends \
    python${PYTHON_VERSION} \
    python${PYTHON_VERSION}-dev \
    python${PYTHON_VERSION}-venv \
    git \
    tesseract-ocr \
    tesseract-ocr-eng \
    tesseract-ocr-osd \
    libtesseract-dev \
    libleptonica-dev \
    libgl1-mesa-glx \
    && rm -rf /var/lib/apt/lists/*

# Set Python 3.12 as default and install pip
RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 1 && \
    curl -sS https://bootstrap.pypa.io/get-pip.py | python3

# Create app user
RUN useradd -m -u 1001 -s /bin/bash appuser

WORKDIR /opt/app-root/src

# Install uv
RUN curl -LsSf https://astral.sh/uv/0.7.19/install.sh | sh && \
    mv /root/.local/bin/uv /usr/local/bin/

# Set environment variables
ENV OMP_NUM_THREADS=4 \
    LANG=en_US.UTF-8 \
    LC_ALL=en_US.UTF-8 \
    PYTHONIOENCODING=utf-8 \
    TRANSFORMERS_VERBOSITY=info \
    UV_COMPILE_BYTECODE=1 \
    UV_LINK_MODE=copy \
    UV_PROJECT_ENVIRONMENT=/opt/app-root \
    DOCLING_SERVE_ARTIFACTS_PATH=/opt/app-root/src/.cache/docling/models \
    TESSDATA_PREFIX=/usr/share/tesseract-ocr/5/tessdata/

# Copy flash-attention wheel from builder
COPY --from=flash-attn-builder /wheels/*.whl /tmp/

# Copy project files
COPY --chown=1001:0 pyproject.toml uv.lock ./

# Install dependencies (excluding flash-attn since we'll install from wheel)
RUN --mount=type=cache,target=/root/.cache/uv,sharing=locked \
    uv sync --frozen --no-install-project --no-dev --all-extras --no-extra flash-attn

# Install the pre-built flash-attention wheel
RUN --mount=type=cache,target=/root/.cache/pip,sharing=locked \
    pip3 install /tmp/flash-attn*.whl && rm -f /tmp/*.whl

# Copy pre-downloaded models
COPY --from=model-downloader --chown=1001:0 /models ${DOCLING_SERVE_ARTIFACTS_PATH}

# Copy application
COPY --chown=1001:0 ./docling_serve ./docling_serve

# Install the application
RUN --mount=type=cache,target=/root/.cache/uv,sharing=locked \
    uv sync --frozen --no-dev --all-extras

# Fix permissions
RUN chown -R 1001:0 /opt/app-root && \
    chmod -R g=u /opt/app-root

USER 1001

EXPOSE 5001

CMD ["docling-serve", "run"]